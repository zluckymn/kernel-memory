# What are prompts?  什么是提示？

- 05/20/2025

Prompts play a crucial role in communicating and directing the behavior of Large Language Models (LLMs) AI. They serve as inputs or queries that users can provide to elicit specific responses from a model.
提示在沟通和指导大型语言模型 （LLM） AI 的行为方面发挥着至关重要的作用。它们充当用户可以提供的输入或查询，以从模型中引出特定响应。



## The subtleties of prompting 提示的微妙之处

Effective prompt design is essential to achieving desired outcomes with LLM AI models. Prompt engineering, also known as prompt design, is an emerging field that requires creativity and attention to detail. It involves selecting the right words, phrases, symbols, and formats that guide the model in generating high-quality and relevant texts.
有效的提示设计对于使用 LLM AI 模型实现预期结果至关重要。提示工程，也称为提示设计，是一个需要创造力和对细节的关注的新兴领域。它涉及选择正确的单词、短语、符号和格式来指导模型生成高质量和相关的文本。

If you've already experimented with ChatGPT, you can see how the model's behavior changes dramatically based on the inputs you provide. For example, the following prompts produce very different outputs:
如果您已经尝试过 ChatGPT，您可以看到模型的行为如何根据您提供的输入发生巨大变化。例如，以下提示会产生非常不同的输出：

Prompt  提示Copy  复制

```Prompt
Please give me the history of humans.
```

Prompt  提示Copy  复制

```Prompt
Please give me the history of humans in 3 sentences.
```

The first prompt produces a long report, while the second prompt produces a concise response. If you were building a UI with limited space, the second prompt would be more suitable for your needs. Further refined behavior can be achieved by adding even more details to the prompt, but its possible to go too far and produce irrelevant outputs. As a prompt engineer, you must find the right balance between specificity and relevance.
第一个提示生成长报告，而第二个提示生成简洁的响应。如果您正在构建空间有限的 UI，则第二个提示将更适合您的需求。通过向提示添加更多细节可以实现进一步细化的行为，但可能会走得太远并产生不相关的输出。作为提示工程师，您必须在特异性和相关性之间找到适当的平衡。

When you work directly with LLM models, you can also use other controls to influence the model's behavior. For example, you can use the `temperature` parameter to control the randomness of the model's output. Other parameters like top-k, top-p, frequency penalty, and presence penalty also influence the model's behavior.
直接使用 LLM 模型时，还可以使用其他控件来影响模型的行为。例如，您可以使用`温度`参数来控制模型输出的随机性。其他参数，如 top-k、top-p、频率惩罚和存在惩罚也会影响模型的行为。



## Prompt engineering: a new career 提示工程：新的职业

Because of the amount of control that exists, prompt engineering is a critical skill for anyone working with LLM AI models. It's also a skill that's in high demand as more organizations adopt LLM AI models to automate tasks and improve productivity. A good prompt engineer can help organizations get the most out of their LLM AI models by designing prompts that produce the desired outputs.
由于存在大量的控制，提示工程对于任何使用 LLM AI 模型的人来说都是一项关键技能。随着越来越多的组织采用 LLM AI 模型来自动执行任务并提高生产力，这也是一项需求量很大的技能。优秀的提示工程师可以通过设计产生所需输出的提示来帮助组织充分利用其 LLM AI 模型。



### Becoming a great prompt engineer with Semantic Kernel 使用Semantic Kernel成为一名出色的提示工程师

Semantic Kernel is a valuable tool for prompt engineering because it allows you to experiment with different prompts and parameters across multiple different models using a common interface. This allows you to quickly compare the outputs of different models and parameters, and iterate on prompts to achieve the desired results.
Semantic Kernel是提示工程的宝贵工具，因为它允许您使用通用接口跨多个不同模型试验不同的提示和参数。这使您可以快速比较不同模型和参数的输出，并迭代提示以达到所需的结果。

Once you've become familiar with prompt engineering, you can also use Semantic Kernel to apply your skills to real-world scenarios. By combining your prompts with native functions and connectors, you can build powerful AI-powered applications.
熟悉提示工程后，还可以使用Semantic Kernel将技能应用到实际场景中。通过将提示与本机函数和连接器相结合，您可以构建强大的人工智能驱动的应用程序。

Lastly, by deeply integrating with Visual Studio Code, Semantic Kernel also makes it easy for you to integrate prompt engineering into your existing development processes.
最后，通过与 Visual Studio Code 深度集成，Semantic Kernel还使你可以轻松地将提示工程集成到现有的开发流程中。

- Create prompts directly in your preferred code editor.
  直接在您喜欢的代码编辑器中创建提示。
- Write tests for them using your existing testing frameworks.
  使用现有的测试框架为它们编写测试。
- And deploy them to production using your existing CI/CD pipelines.
  并使用现有的 CI/CD 管道将它们部署到生产环境。



### Additional tips for prompt engineering 提示工程的其他提示

Becoming a skilled prompt engineer requires a combination of technical knowledge, creativity, and experimentation. Here are some tips to excel in prompt engineering:
成为一名熟练的提示工程师需要技术知识、创造力和实验的结合。以下是在提示工程方面表现出色的一些技巧：

- **Understand LLM AI models:** Gain a deep understanding of how LLM AI models work, including their architecture, training processes, and behavior.
  **了解 LLM AI 模型：** 深入了解 LLM AI 模型的工作原理，包括其架构、训练过程和行为。
- **Domain knowledge:** Acquire domain-specific knowledge to design prompts that align with the desired outputs and tasks.
  **领域知识：** 获取特定领域的知识，以设计与所需输出和任务相符的提示。
- **Experimentation:** Explore different parameters and settings to fine-tune prompts and optimize the model's behavior for specific tasks or domains.
  **实验：** 探索不同的参数和设置以微调提示并优化特定任务或域的模型行为。
- **Feedback and iteration:** Continuously analyze the outputs generated by the model and iterate on prompts based on user feedback to improve their quality and relevance.
  **反馈与迭代：** 持续分析模型生成的输出，并根据用户反馈迭代提示，以提高其质量和相关性。
- **Stay updated:** Keep up with the latest advancements in prompt engineering techniques, research, and best practices to enhance your skills and stay ahead in the field.
  **保持更新：** 跟上提示工程技术、研究和最佳实践的最新进展，以提高您的技能并在该领域保持领先地位。

Prompt engineering is a dynamic and evolving field, and skilled prompt engineers play a crucial role in harnessing the capabilities of LLM AI models effectively.
提示工程是一个充满活力且不断发展的领域，熟练的提示工程师在有效利用 LLM AI 模型的功能方面发挥着至关重要的作用。



## Next steps  后续步骤

​     