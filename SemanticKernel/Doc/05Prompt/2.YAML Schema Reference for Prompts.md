# YAML schema reference for Semantic Kernel prompts Semantic Kernel提示的 YAML 架构参考

- 12/03/2024

The YAML schema reference for Semantic Kernel prompts is a detailed reference for YAML prompts that lists all supported YAML syntax and their available options.
Semantic Kernel提示的 YAML 架构参考是 YAML 提示的详细参考，其中列出了所有受支持的 YAML 语法及其可用选项。



## Definitions  定义



### name  名字

The function name to use by default when creating prompt functions using this configuration. If the name is null or empty, a random name will be generated dynamically when creating a function.
使用此配置创建提示函数时默认使用的函数名称。如果名称为 null 或空，则在创建函数时将动态生成一个随机名称。



### description  描述

The function description to use by default when creating prompt functions using this configuration.
使用此配置创建提示函数时默认使用的函数描述。



### template_format

The identifier of the Semantic Kernel template format. Semantic Kernel provides support for the following template formats:
Semantic Kernel模板格式的标识符。Semantic Kernel支持以下模板格式：

1. [semantic-kernel](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/prompt-template-syntax) - Built-in Semantic Kernel format.
   [semantic-kernel](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/prompt-template-syntax) - 内置Semantic Kernel格式。
2. [handlebars](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/handlebars-prompt-templates) - Handlebars template format.
   [handlebars](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/handlebars-prompt-templates) - 车把模板格式。
3. [liquid](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/liquid-prompt-templates) - Liquid template format
   [liquid](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/liquid-prompt-templates) - 液体模板格式



### template  模板

The prompt template string that defines the prompt.
定义提示的提示模板字符串。



### input_variables

The collection of input variables used by the prompt template. Each input variable has the following properties:
提示模板使用的输入变量的集合。每个输入变量都具有以下属性：

1. `name` - The name of the variable.
   `name` - 变量的名称。
2. `description` - The description of the variable.
   `description` - 变量的描述。
3. `default` - An optional default value for the variable.
   `default` - 变量的可选默认值。
4. `is_required` - Whether the variable is considered required (rather than optional). Default is `true`.
   `is_required` - 变量是否被视为必需（而不是可选）。默认值为 `true`。
5. `json_schema` - An optional JSON Schema describing this variable.
   `json_schema` - 描述此变量的可选 JSON 架构。
6. `allow_dangerously_set_content` - A boolean value indicating whether to handle the variable value as potential dangerous content. Default is `false`. See [Protecting against Prompt Injection Attacks](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/prompt-injection-attacks) for more information.
   `allow_dangerously_set_content` - 一个布尔值，指示是否将变量值作为潜在危险内容进行处理。默认值为 `false`。有关详细信息，请参阅防[范提示注入攻击 ](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/prompt-injection-attacks)。

 Tip  提示

The default for `allow_dangerously_set_content` is false. When set to true the value of the input variable is treated as safe content. For prompts which are being used with a chat completion service this should be set to false to protect against prompt injection attacks. When using other AI services e.g. Text-To-Image this can be set to true to allow for more complex prompts.
`allow_dangerously_set_content` 的默认值为 false。当设置为 true 时，输入变量的值将被视为安全内容。对于与聊天完成服务一起使用的提示，应将其设置为 false 以防止提示注入攻击。当使用其他 AI 服务（例如文本到图像）时，可以将其设置为 true 以允许更复杂的提示。



### output_variable

The output variable used by the prompt template. The output variable has the following properties:
提示模板使用的输出变量。输出变量具有以下属性：

1. `description` - The description of the variable.
   `description` - 变量的描述。
2. `json_schema` - The JSON Schema describing this variable.
   `json_schema` - 描述此变量的 JSON 架构。



### execution_settings

The collection of execution settings used by the prompt template. The execution settings are a dictionary which is keyed by the service ID, or `default` for the default execution settings. The service id of each [PromptExecutionSettings](https://learn.microsoft.com/en-us/dotnet/api/microsoft.semantickernel.promptexecutionsettings) must match the key in the dictionary.
提示模板使用的执行设置集合。执行设置是一个字典，由服务 ID 键入，或默认执行设置的`默认`值。每个 [PromptExecutionSettings](https://learn.microsoft.com/en-us/dotnet/api/microsoft.semantickernel.promptexecutionsettings) 的服务 ID 必须与字典中的键匹配。

Each entry has the following properties:
每个条目都有以下属性：

1. `service_id` - This identifies the service these settings are configured for e.g., azure_openai_eastus, openai, ollama, huggingface, etc.
   `service_id` - 这标识了为这些设置配置的服务，例如 azure_openai_eastus、openai、ollama、huggingface 等。
2. `model_id` - This identifies the AI model these settings are configured for e.g., gpt-4, gpt-3.5-turbo.
   `model_id` - 这标识了为这些设置配置的 AI 模型，例如 gpt-4、gpt-3.5-turbo。
3. `function_choice_behavior` - The behavior defining the way functions are chosen by LLM and how they are invoked by AI connectors. For more information see [Function Choice Behaviors](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling/function-choice-behaviors)
   `function_choice_behavior` - 定义 LLM 选择函数的方式以及 AI 连接器如何调用函数的行为。有关详细信息 [，请参阅函数选择行为](https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/function-calling/function-choice-behaviors)

 Tip  提示

If provided, the service identifier will be the key in a dictionary collection of execution settings. If not provided the service identifier will be set to `default`.
如果提供，则服务标识符将是执行设置字典集合中的键。如果未提供，则服务标识符将设置为`默认`值。



#### Function Choice Behavior  函数选择行为

To disable function calling, and have the model only generate a user-facing message, set the property to null (the default).
若要禁用函数调用，并让模型仅生成面向用户的消息，请将属性设置为 null （默认值） 。

- `auto` - To allow the model to decide whether to call the functions and, if so, which ones to call.
  `auto` - 允许模型决定是否调用函数，如果是，则决定调用哪些函数。
- `required` - To force the model to always call one or more functions.
  `required` - 强制模型始终调用一个或多个函数。
- `none` - To instruct the model to not call any functions and only generate a user-facing message.
  `none` - 指示模型不调用任何函数，仅生成面向用户的消息。



### allow_dangerously_set_content

A boolean value indicating whether to allow potentially dangerous content to be inserted into the prompt from functions. **The default is false.** When set to true the return values from functions only are treated as safe content. For prompts which are being used with a chat completion service this should be set to false to protect against prompt injection attacks. When using other AI services e.g. Text-To-Image this can be set to true to allow for more complex prompts. See [Protecting against Prompt Injection Attacks](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/prompt-injection-attacks) for more information.
一个布尔值，指示是否允许将潜在危险的内容插入到函数的提示中。 **默认值为 false。** 当设置为 true 时，仅函数的返回值被视为安全内容。 对于与聊天完成服务一起使用的提示，应将其设置为 false 以防止提示注入攻击。 当使用其他 AI 服务（例如文本到图像）时，可以将其设置为 true 以允许更复杂的提示。 有关详细信息，请参阅防[范提示注入攻击 ](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/prompt-injection-attacks)。



## Sample YAML prompt  示例 YAML 提示

Below is a sample YAML prompt that uses the [Handlebars template format](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/handlebars-prompt-templates) and is configured with different temperatures when be used with `gpt-3` and `gpt-4` models.
下面是一个示例 YAML 提示，它使用 [Handlebars 模板格式 ](https://learn.microsoft.com/en-us/semantic-kernel/concepts/prompts/handlebars-prompt-templates)，并在与 `gpt-3` 和 `gpt-4` 模型一起使用时配置了不同的温度。

ymlCopy  复制

```yml
name: GenerateStory
template: |
  Tell a story about {{topic}} that is {{length}} sentences long.
template_format: handlebars
description: A function that generates a story about a topic.
input_variables:
  - name: topic
    description: The topic of the story.
    is_required: true
  - name: length
    description: The number of sentences in the story.
    is_required: true
output_variable:
  description: The generated story.
execution_settings:
  service1:  
    model_id: gpt-4
    temperature: 0.6
  service2:
    model_id: gpt-3
    temperature: 0.4
  default:
    temperature: 0.5
```



## Next steps  后续步骤

 